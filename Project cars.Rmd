---
title: "Big Data project"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
setwd("/Users/dua/Documents/Big Data Analytics/Project")
library("ggplot2")
library(readxl)
library(naivebayes)
```

#1) Energy efficiency data set 
https://archive.ics.uci.edu/ml/datasets/energy+efficiency#


```{r}
data2<-read_excel("energy_data.xlsx", sheet = 1, col_names = TRUE)
colnames(data2)=c("rel.compact", "surface", "wall.area","roof.area","height","orientation","glazing","glazing.distribution","heating.load","cooling.load")
data2[0:10,]

p<-ggplot(data2,aes(x=roof.area,y=heating.load))+geom_point(aes(colour=orientation), position="jitter")
p
```

#2) Car evaluation data set
http://archive.ics.uci.edu/ml/datasets/Car+Evaluation


```{r}
data<- read.table("car.data", sep="," , header=T)
colnames(data) <- c("Buying_price", "Maintenance_price", "Doors", "Persons", "Lug_boot", "Safety","Value")
levels(data$Doors)

```

Description des variables: 
- Buying price and maintenance price: low, med, high, very high
- Number of doors: 2, 3, 4, 5 or more
- Max number of people: 2, 4, or more
- Size of luggage boot: small, medium, big
- Safety index: low, medium, high

- Value of car: what we are trying to predict. Unacceptable, acceptable, good, very good

```{r}
#Reorder the variable scales from low to high
data$Buying_price<-factor(data$Buying_price, levels=c("low","med","high","vhigh"))
data$Maintenance_price<-factor(data$Maintenance_price, levels=c("low","med","high","vhigh"))
data$Value<-factor(data$Value, levels=c("unacc","acc","good","vgood"))
data$Lug_boot<-factor(data$Lug_boot, levels=c("small","med","big"))
data$Safety<-factor(data$Safety, levels=c("low","med","high"))

data2 <-subset(data, (data$Doors!=4 | data$Persons!=2) & (data$Doors!="5more" | data$Persons!=2))
data3<- subset(data2, data2$Buying_price!="med" & data2$Maintenance_price!="med")

#attach(data2)
attach(data3)
length(Safety)
summary(data2)

data3$value2<-as.numeric(data3$Value)

```
Nb of rows in data2: 1439
```{r}
#Roughly explore the influence of each parameter on the Value
graph<-ggplot(data2,aes(x=Safety,y=Value))+geom_point(position = "jitter")
graph

graph<-ggplot(data2,aes(x=Buying_price,y=Value))+geom_point(position = "jitter")
graph

graph<-ggplot(data2,aes(x=Maintenance_price,y=Value))+geom_point(position = "jitter")
graph

graph<-ggplot(data2,aes(x=Doors,y=Value))+geom_point(position = "jitter")
graph

graph<-ggplot(data2,aes(x=Persons,y=Value))+geom_point(position = "jitter")
graph

graph<-ggplot(data2,aes(x=Lug_boot,y=Value))+geom_point(position = "jitter")
graph

graph<-ggplot(data2,aes(x=Doors,y=Persons))+geom_point(aes(colour=Value), position = "jitter")
graph
```
Temporary conclusions: 

- Safety is a quite important factor: a low safety automatically results in "Unacceptable"
- Buying price: if high or very high, results in "unacc" or "acc" at best
- Maintenance price: if very high, results in "unacc" or "acc", but some cars with "high" maintenance price (sign of a good quality?) are "very good"
- Number of doors: irrelevant in determining value at first glance because the proportions of unacc, acc, good and vgood seem to not depend on the number of doors
- Max number of passengers: "2 people" means a car that is too small --> unacc. Indifferent between 4 people or more
- Size of luggage loot: not very relevant but a small loot cannot result in "very good"


Plot histogram because many points may be overlapped

```{r}
#To see how the data is distributed (proportions)
naive_bayes(data2,Lug_boot)
```
```{r}
#Logistic regression: Model that includes Lug_boot size and safety in predicting the Value

glmfit<-glm(Value~Lug_boot + Safety,family=binomial)
proba <- predict(glmfit,type="response")

#lugboot <- as.numeric(Lug_boot)
#curve <- data.frame(value2,proba,Lug_boot)
#ggplot(curve,aes(Lug_boot,proba))+geom_point(position="jitter")+ #geom_point(aes(x=Lug_boot,y=value2),color="orange")

summary(glmfit)
length(value2)

```
```{r}
#Model that includes all the parameters in predicting the Value

glmfit<-glm(Value~ Buying_price + Doors + Maintenance_price + Lug_boot,family=binomial,data=data3)

proba <- predict(glmfit,type="response")
summary(proba)

dataframe<-data.frame(proba)

p <- ggplot(dataframe, aes(proba)) + geom_histogram(aes(y=..density..), colour="black", fill="white") + geom_density(alpha=.2, fill="#FF6666")
p

summary(glmfit)

```
Conclusions: 
Number of doors totally irrelevant (p-value is too large)
It appears that safety is irrelevant (p-value too large). Why??
```{r}
glm.probs=predict(glmfit,type="response",data=data3)
glm.pred = rep(1,nrow(data3))# creates a vector of 1 elements 

#Function that returns the vector with associates to each car its predicted Value, depending on the chosen thresholds for the probabilities
result.table<-function(p1,p2,p3){
  glm.pred[glm.probs>=p1]=4 #transforms to 1 all of the elements for which th e predicted
  glm.pred[(glm.probs>=p2) & (glm.probs<p1)]=3
  glm.pred[glm.probs>=p3 & glm.probs<p2]=2
  
  return(glm.pred)
}


optim<-function(p1,p2,p3,pas){
  results<-list()
  p1bis=p1
  while(p1bis<1){
    p2bis=p2
    while (p2bis<p1bis){
      p3bis=p3
      while (p3bis<p2bis) {
        confusion.matrix=table(result.table(p1bis,p2bis,p3bis),data3$value2)
        precision=sum(diag(confusion.matrix))/nrow(data3)
        results=c(results,list(c(p1bis,p2bis,p3bis,precision)))
        p3bis=p3bis+pas
      }
      p2bis=p2bis+pas
    }
    p1bis=p1bis+pas
  }
  
  d<-as.data.frame(results)
  return(d)
}

q<-optim(0.2,0.15,0.1,0.05)
q<-t(q) #transpose q
q<-as.data.frame(q) #converts to data frame

#Renaming rows and columns
colnames(q)<-c("p1","p2","p3","Precision")
rownames(q)<-c()

#Extracting the maximum precision and its associated threshold probability
qbis<-subset(q, (q$Precision==max(q$Precision)))
qbis
```


```{r}
confusion.matrix<-table(result.table(0.8,0.75,0.3),value2)
confusion.matrix

precision=sum(diag(confusion.matrix))/nrow(data3)
precision

nrow(data3)
```

```{r}
glm.probs=predict(glmfit,type="response",data=data2)
glm.pred = rep(1,nrow(data2))# creates a vector of 1 elements 

#Function that returns the vector with associates to each car its predicted Value, depending on the chosen thresholds for the probabilities
result.table<-function(p1,p2,p3){
  glm.pred[glm.probs>=p1]=4 #transforms to 1 all of the elements for which th e predicted
  glm.pred[(glm.probs>=p2) & (glm.probs<p1)]=3
  glm.pred[glm.probs>=p3 & glm.probs<p2]=2
  
  return(glm.pred)
}

data2$value2<-as.numeric(data2$Value)
confusion.matrix.test<-table(result.table(0.85,0.8,0.75),data2$value2)
confusion.matrix.test

precision.test=sum(diag(confusion.matrix.test))/nrow(data2)
precision.test
```

